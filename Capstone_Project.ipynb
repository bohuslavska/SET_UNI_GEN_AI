{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7K9KEv3vdEzk"
      },
      "outputs": [],
      "source": [
        "# ! pip install streamlit\n",
        "# ! pip install --upgrade --quiet unstructured\n",
        "# ! pip install langchain_community\n",
        "# ! pip install unstructured\n",
        "# ! pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8hJaymOxdA-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70dfbdf-d962-4c84-dd83-4c1b0137805d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Imports\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "import openai\n",
        "import time\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "import streamlit as st\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import altair as alt\n",
        "from datetime import date\n",
        "import plotly.express as px\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3SDqJes19WUJ"
      },
      "outputs": [],
      "source": [
        "# Project constants\n",
        "\n",
        "today = str(date.today())\n",
        "\n",
        "with open(\"/content/api_key.txt\", \"r\") as file:\n",
        "    key = file.read().strip()\n",
        "\n",
        "model = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDlLeZm9WUK"
      },
      "source": [
        "# Scraping and Downloading Data From Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w2rGms-6UDX8"
      },
      "outputs": [],
      "source": [
        "# Djinni allows to scrape only the first 15 vacancies:(\n",
        "# At least something unlike DOU\n",
        "\n",
        "def scrape_list_page():\n",
        "    page_url = f\"https://djinni.co/jobs/?primary_keyword=Data+Science&primary_keyword=ML+AI&exp_level=2y&exp_level=3y&exp_level=4y&page=1\"\n",
        "    try:\n",
        "        # Send an HTTP GET request to the current page, as far as it successful parsing continues\n",
        "        response = requests.get(page_url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            # Find all anchor tags with the specified class\n",
        "            job_links = soup.select('a.job-item__title-link')\n",
        "            # Extract the 'href' attribute from each link and supplement it to the full URL\n",
        "            start = 'https://djinni.co'\n",
        "            job_urls = [start + link['href'] for link in job_links if 'href' in link.attrs]\n",
        "            # Append the URLs to the list\n",
        "            return list(set(job_urls))\n",
        "        else:\n",
        "            print(f\"Non-200 response for {page_url}: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred on {page_url}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-1n4pCKZi-X",
        "outputId": "6569ab42-9fd1-4488-d644-dcd2be0be026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 15 URLs scraped!\n"
          ]
        }
      ],
      "source": [
        "# Djinni blocked our IP address entirely:(\n",
        "# But we still have some vacancies in the bucket:D\n",
        "def getting_urls():\n",
        "    try:\n",
        "        scraped_urls = scrape_list_page()\n",
        "        if len(scraped_urls) > 0:\n",
        "            print(f'There are {len(scraped_urls)} URLs scraped!')\n",
        "            return scraped_urls\n",
        "        else:\n",
        "            scraped_urls = []\n",
        "            return scraped_urls\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while scraping: {e}\")\n",
        "        scraped_urls = []\n",
        "        return scraped_urls\n",
        "\n",
        "scraped_urls = getting_urls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n2mzcEK9WUO",
        "outputId": "0321842e-0654-4535-b539-9ab61a824d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 82 extracted URLs.\n"
          ]
        }
      ],
      "source": [
        "# Let's extract from downloaded data links to the vacancies via regex expression\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Set_Uni\"\n",
        "urls_from_txts = []\n",
        "# Regex pattern to find HTTPS URLs\n",
        "# Matches URLs starting with http or https\n",
        "url_pattern = r\"https?://[^\\s]+\"\n",
        "\n",
        "# Loop over all files in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    if file_name.endswith(\".txt\"):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            content = file.read()\n",
        "            urls = re.findall(url_pattern, content)\n",
        "            if urls:\n",
        "                urls_from_txts.append(urls[0])\n",
        "\n",
        "print(f\"There are {len(urls_from_txts)} extracted URLs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "up-5Kiji9WUN"
      },
      "outputs": [],
      "source": [
        "#############Alternative: Downloading from the S3 Bucket###############\n",
        "# Define S3 bucket and folders\n",
        "# bucket_name = \"raw-job-descriptions\"\n",
        "# s3_folder = \"raw-txt-job/\"\n",
        "# local_folder = \"job_data/\"\n",
        "\n",
        "# # Ensure the local folder exists\n",
        "# os.makedirs(local_folder, exist_ok=True)\n",
        "\n",
        "# # List files in the S3 folder\n",
        "# response = s3.list_objects_v2(Bucket=bucket_name, Prefix=s3_folder)\n",
        "\n",
        "# # Download each file\n",
        "# if 'Contents' in response:\n",
        "#     for obj in response['Contents']:\n",
        "#         file_key = obj['Key']\n",
        "#         file_name = file_key.split(\"/\")[-1]\n",
        "#         local_file_path = os.path.join(local_folder, file_name)\n",
        "#         if not file_name:\n",
        "#             continue\n",
        "#         print(f\"Downloading {file_key} to {local_file_path}...\")\n",
        "#         s3.download_file(bucket_name, file_key, local_file_path)\n",
        "#     print(\"Download complete.\")\n",
        "# else:\n",
        "#     print(\"No files found in the specified folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn6GNowW9WUO",
        "outputId": "eb67165b-0420-47c1-f650-0a006d64a620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totally we have 97 URLs.\n"
          ]
        }
      ],
      "source": [
        "total_urls = scraped_urls + urls_from_txts\n",
        "print(f'Totally we have {len(total_urls)} URLs.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpGnM_oT707",
        "outputId": "28336a31-0923-41b5-cf6c-391441dbe06b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example: page_content='Error\n",
            "\n",
            "All jobs\n",
            "\n",
            "Data and Analytics\n",
            "\n",
            "Data Science\n",
            "\n",
            "ML / AI\n",
            "\n",
            "Kyiv\n",
            "\n",
            "AI Engineer\n",
            "\n",
            "PlayMe Studio\n",
            "\n",
            "About the role:\n",
            "\n",
            "We are seeking a talented AI Engineer to join our team and drive the development of the core of our web AI product. As an AI Engineer, you will play a pivotal role in shaping the future of our product by being responsible for the LLM stack, its improvement, and deployment.\n",
            "\n",
            "Areas of responsibility:\n",
            "\n",
            "Designing and implementing LLM API integrations with various providers (e.g., OpenAI, Anthropic, Cohere, Meta);\n",
            "\n",
            "Developing and optimizing prompt engineering strategies to enhance model performance and ensure consistent, high-quality outputs;\n",
            "\n",
            "Creating and maintaining multi-agent and multi-modal workflows (text, image, speech generation);\n",
            "\n",
            "Implementing safeguards and validation mechanisms to prevent hallucinations and ensure compliance with regulations;\n",
            "\n",
            "‚Äã‚ÄãImplementing and optimizing image generation capabilities with character consistency (custom ComfyUI workflows or similar solutions).\n",
            "\n",
            "Developing and maintaining a robust infrastructure for training, deploying, and monitoring LLM models in collaboration with our DevOps/MLOps team;\n",
            "\n",
            "Collaborating closely with the product team to gather user feedback and incorporate it into the LLM training process;\n",
            "\n",
            "Generating comprehensive reports and demos to showcase the capabilities and progress of our LLM.\n",
            "\n",
            "Your skills and experience:\n",
            "\n",
            "3+ years of experience working with LLM APIs and implementing AI-powered features in production environments;\n",
            "\n",
            "Strong expertise in prompt engineering, including chain-of-thought prompting, few-shot learning, and system prompting;\n",
            "\n",
            "Experience designing and implementing chatbots, multi-agent systems and workflows using Langchain, LlamaIndex or similar frameworks;\n",
            "\n",
            "Proficiency in Python and API integration;\n",
            "\n",
            "Strong understanding of the Product Development Lifecycle to adapt experiments and knowledge sharing sessions based on the current stage of product development;–≤\n",
            "\n",
            "Ability to effectively present modeling performance results and data insights.\n",
            "\n",
            "Will be a plus if you:\n",
            "\n",
            "Have experience with React/Next.js frontend development;\n",
            "\n",
            "Experience with vector databases and semantic search implementations;\n",
            "\n",
            "Experience with machine learning model training and fine-tuning;\n",
            "\n",
            "Experience with image generation tools (SDXL, ComfyUI, Stable Diffusion) and workflows.\n",
            "\n",
            "We offer:\n",
            "\n",
            "You will be working with a professional and motivated team of enthusiasts in the environment that brings up the best in everyone. We have no bureaucracy, and we give our colleagues complete freedom to make decisions and achieve brilliant results.\n",
            "\n",
            "Our company is built on the ability to find the best people and provide them with everything needed to stay focused on what‚Äôs important to make our users even healthier, sportier, happier and better! We create a business environment that brings up the best in everyone.\n",
            "\n",
            "Competitive salary. Compensation that will help you focus on your projects and personal development.\n",
            "\n",
            "Professional Growth. We offer a possibility to attend internal, external courses, seminars and access to a corporate library. You will be working with a team of professionals to get insights and discuss ideas.\n",
            "\n",
            "Health & Fitness. We provide employees with 20 days of paid vacation, medical insurance and a variety of sports activities available for employees inside and outside the office.\n",
            "\n",
            "Rest. We organize team buildings and various team activities to boost our collaboration.\n",
            "\n",
            "To apply for this and other jobs on Djinni login or signup.\n",
            "\n",
            "Only from Intermediate\n",
            "\n",
            "Required knowledge of Ukrainian\n",
            "\n",
            "Only from 3 years of experience\n",
            "\n",
            "Office or Remote\n",
            "\n",
            "Worldwide\n",
            "\n",
            "Countries where we consider candidates\n",
            "\n",
            "ML / AI\n",
            "\n",
            "Domain: Other\n",
            "\n",
            "Product\n",
            "\n",
            "Office: Ukraine (Kyiv)\n",
            "\n",
            "Apply for the job\n",
            "\n",
            "üìä Average salary range of similar jobs in analytics ‚Üí\n",
            "\n",
            "Similar jobs\n",
            "\n",
            "Senior Deep Learning Engineer (NLP / CV / GenAI) at Anadea\n",
            "\n",
            "Countries of Europe or Ukraine\n",
            "\n",
            "Full Ukrainian Development Team for AI-Powered Sports Betting App at Winbets\n",
            "\n",
            "Ukraine\n",
            "\n",
            "Mainframe Developer at GlobalLogic\n",
            "\n",
            "Romania\n",
            "\n",
            "All jobs ML AI Kyiv ‚Üí\n",
            "\n",
            "All jobs PlayMe Studio ‚Üí\n",
            "\n",
            "Terms\n",
            "\n",
            "Privacy\n",
            "\n",
            "Suggest an idea\n",
            "\n",
            "Support' metadata={'source': 'https://djinni.co/jobs/712318-ai-engineer/'}\n",
            "\n",
            "The unstructured data has been successfully loaded!\n"
          ]
        }
      ],
      "source": [
        "# Let's load pages with the help of Langchain UnstructuredURLLoader\n",
        "if total_urls:\n",
        "    try:\n",
        "        loader = UnstructuredURLLoader(urls=total_urls)\n",
        "        data_scraped = loader.load()\n",
        "        print('Example:', data_scraped[0])\n",
        "        print(\"\\nThe unstructured data has been successfully loaded!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data from URLs: {e}\")\n",
        "else:\n",
        "    print(\"\\nNo URLs extracted. Skipping UnstructuredURLLoader:(\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR15YYXi9WUP"
      },
      "source": [
        "# Information extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MKlgKT0PT8Y7"
      },
      "outputs": [],
      "source": [
        "# Prompt for important information extraction (with examples)\n",
        "\n",
        "def prompting(job_description):\n",
        "    prompt_general = f\"\"\"Your task is to analyze the current job market state.\n",
        "    To do so read the job description and return JSON with specific information.\n",
        "    The description may be written in Ukrainian, English, or a mix of both.\n",
        "    It may contain short info from other job descriptions, ignore it, and focus on the main topic.\n",
        "    Instructions:\n",
        "    1. Extract the following details from each job description:\n",
        "    - Company name\n",
        "    - Title\n",
        "    - Hard skills required (specific technologies, programming languages, frameworks, tools)\n",
        "    - Soft skills required (e.g., English proficiency, communication skills, teamwork)\n",
        "    - Education requirements (whether a degree is required or if experience alone is sufficient)\n",
        "    2. Return information from a job description, strictly following the format of the examples below.\n",
        "    Examples:\n",
        "    {{\n",
        "      \"company_name\": \"UkrSoft\",\n",
        "      \"title_name\": \"Middle Machine Learning Engineer\",\n",
        "      \"hard_skills_technologies\": [\n",
        "        \"Python\", \"R\", \"Scikit-learn\", \"XGBoost\", \"CatBoost\", \"TensorFlow\",\n",
        "        \"SQL\", \"Spark\", \"–†–µ–≥—Ä–µ—Å—ñ—ó\", \"–¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å\", \"—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –º–µ—Ç–æ–¥–∏\",\n",
        "        \"image recognition algorithms\", \"deploying image recognition algorithms\", \"deep learning\"\n",
        "      ],\n",
        "      \"soft_skills\": [\"advanced English\", \"profound communication skills\"],\n",
        "      \"education\": \"MS in mathematics or statistics\"\n",
        "    }},\n",
        "\n",
        "    {{\n",
        "      \"company_name\": \"HardServe\",\n",
        "      \"title_name\": \"Junior Data Scientist\",\n",
        "      \"hard_skills_technologies\": [\n",
        "        \"LLM proficiency\", \"evaluate model performance\", \"MySQL\", \"PostgreSQL\", \"SAP IQ\",\n",
        "        \"ETL —Å–µ—Ä–≤—ñ—Å–∏ AWS\", \"Tableau REST API\", \"Hugging Face Transformers\",\n",
        "        \"Machine learning algorithms\", \"Anthropic Models\", \"Pandas\",\n",
        "        \"Apache Spark (pyspark)\", \"Apache Kafka\", \"Git\", \"–º–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó\"\n",
        "      ],\n",
        "      \"soft_skills\": [\"being a team player\", \"excellent presenting skills\"],\n",
        "      \"education\": \"at least 1 year of experience\"\n",
        "    }}\n",
        "    Job description: {job_description}\"\"\"\n",
        "    return prompt_general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rAhJxFX6T8e3"
      },
      "outputs": [],
      "source": [
        "# Function for information extraction and response parsing\n",
        "\n",
        "def llm_parsing(description):\n",
        "    \"\"\"\n",
        "    Analyzes and parses scraped data according to the example\n",
        "    \"\"\"\n",
        "    client = openai.OpenAI(api_key=key)\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\"\"\"You are an expert in LLMs, machine learning, and data science.\n",
        "                Analyze the provided description and return your answer strictly\n",
        "                as valid JSON with no extra words.\"\"\")},\n",
        "        {\"role\": \"user\", \"content\": prompting(description)}],\n",
        "        temperature=0.1)\n",
        "    content = response.choices[0].message.content\n",
        "    content = content.replace(\"```\", \"\").strip()\n",
        "    try:\n",
        "        # Attempt to find the first curly brace and slice from there\n",
        "        json_start = content.index(\"{\")\n",
        "        json_text = content[json_start:]\n",
        "        parsed_output = json.loads(json_text)\n",
        "    except (ValueError, json.JSONDecodeError) as e:\n",
        "        print(\"Error parsing JSON (explicit method):\", e)\n",
        "        return None\n",
        "    return parsed_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "CLFIVPJQvSSs",
        "outputId": "7e82db03-c80e-4066-96c9-dbaa1d6f62e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the created analytics dataframe is (97, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    company_name                                         title_name  \\\n",
              "0  PlayMe Studio                                        AI Engineer   \n",
              "1     LL Capital                                   Quant Researcher   \n",
              "2        Respaid           ML engineer ‚Ä¢ Data automation specialist   \n",
              "3   Ocean Script  Backend Developer (Python) with experience in NLP   \n",
              "4    EveryMatrix                                AI/ML Lead Engineer   \n",
              "\n",
              "                            hard_skills_technologies  \\\n",
              "0  [LLM APIs, AI-powered features, prompt enginee...   \n",
              "1  [mathematical modeling, statistical modeling, ...   \n",
              "2  [OPENAI, BERT, CLAUDE, GEMINI, STT, TTS, Pytho...   \n",
              "3  [Python, FastAPI, Flask, Django, NLP models, O...   \n",
              "4  [Python, PyTorch, TensorFlow, scikit-learn, La...   \n",
              "\n",
              "                                         soft_skills  \\\n",
              "0  [strong understanding of the Product Developme...   \n",
              "1                                                 []   \n",
              "2                             [Intermediate English]   \n",
              "3                                                 []   \n",
              "4  [excellent communication skills, English: Uppe...   \n",
              "\n",
              "                                           education  \n",
              "0                             3+ years of experience  \n",
              "1  MSc or PhD in Statistics, Mathematics, Compute...  \n",
              "2  from 2 years of experience, considering with 1...  \n",
              "3                             2+ years of experience  \n",
              "4  Master‚Äôs in Data Science (or related field), o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5507498e-7b95-436a-85fe-33bb6ffaad28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company_name</th>\n",
              "      <th>title_name</th>\n",
              "      <th>hard_skills_technologies</th>\n",
              "      <th>soft_skills</th>\n",
              "      <th>education</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PlayMe Studio</td>\n",
              "      <td>AI Engineer</td>\n",
              "      <td>[LLM APIs, AI-powered features, prompt enginee...</td>\n",
              "      <td>[strong understanding of the Product Developme...</td>\n",
              "      <td>3+ years of experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LL Capital</td>\n",
              "      <td>Quant Researcher</td>\n",
              "      <td>[mathematical modeling, statistical modeling, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>MSc or PhD in Statistics, Mathematics, Compute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Respaid</td>\n",
              "      <td>ML engineer ‚Ä¢ Data automation specialist</td>\n",
              "      <td>[OPENAI, BERT, CLAUDE, GEMINI, STT, TTS, Pytho...</td>\n",
              "      <td>[Intermediate English]</td>\n",
              "      <td>from 2 years of experience, considering with 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ocean Script</td>\n",
              "      <td>Backend Developer (Python) with experience in NLP</td>\n",
              "      <td>[Python, FastAPI, Flask, Django, NLP models, O...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2+ years of experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EveryMatrix</td>\n",
              "      <td>AI/ML Lead Engineer</td>\n",
              "      <td>[Python, PyTorch, TensorFlow, scikit-learn, La...</td>\n",
              "      <td>[excellent communication skills, English: Uppe...</td>\n",
              "      <td>Master‚Äôs in Data Science (or related field), o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5507498e-7b95-436a-85fe-33bb6ffaad28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5507498e-7b95-436a-85fe-33bb6ffaad28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5507498e-7b95-436a-85fe-33bb6ffaad28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ba3839e4-45d4-4a78-8bc5-e80994210128\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba3839e4-45d4-4a78-8bc5-e80994210128')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ba3839e4-45d4-4a78-8bc5-e80994210128 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[:5]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"company_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"LL Capital\",\n          \"EveryMatrix\",\n          \"Respaid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Quant Researcher\",\n          \"AI/ML Lead Engineer\",\n          \"ML engineer \\u2022 Data automation specialist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_skills_technologies\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"soft_skills\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MSc or PhD in Statistics, Mathematics, Computer Science, or Quantitative Finance\",\n          \"Master\\u2019s in Data Science (or related field), or at least 4 years of commercial experience in AI/ML\",\n          \"from 2 years of experience, considering with 1 year of experience\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Create analytics dataframe for the further analysis\n",
        "\n",
        "parsed_info_list = []\n",
        "for d in data_scraped:\n",
        "    result = llm_parsing(d.page_content)\n",
        "    if result is not None:\n",
        "        parsed_info_list.append(result)\n",
        "df = pd.DataFrame(parsed_info_list)\n",
        "print(f\"Shape of the created analytics dataframe is {df.shape}\")\n",
        "df[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates in case of identical vcancies\n",
        "\n",
        "print(f'Original dataset shape: {df.shape}')\n",
        "df = df[~df.duplicated(subset=['company_name', 'title_name'], keep=False)]\n",
        "print(f'Shape after dropping duplicates: {df.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgLmMQ0uZRYd",
        "outputId": "1f9288ec-8e1d-487b-a579-5f11d81b81ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (97, 5)\n",
            "Shape after dropping duplicates: (75, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with only nan values\n",
        "\n",
        "print(f'Original dataset shape: {df.shape}')\n",
        "df = df.dropna(how=\"all\")\n",
        "print(f'Shape after dropping nans: {df.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaM1-3h0a_Ac",
        "outputId": "de12dfe4-c23c-4474-a5f6-e0fb7c8e314e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (75, 5)\n",
            "Shape after dropping nans: (74, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "q5_sR3UIqTIr"
      },
      "outputs": [],
      "source": [
        "# Function for analysis (based on analytics dataframe)\n",
        "\n",
        "def llm_analytics(prom):\n",
        "    \"\"\"\n",
        "    Analyzes and parses data from the analytics table\n",
        "    \"\"\"\n",
        "    client = openai.OpenAI(api_key=key)\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"\"\"You are an expert in LLMs, machine learning, and data science.\n",
        "                You return your answers strictly as valid JSON with no extra words.\"\"\"},\n",
        "                  {\"role\": \"user\", \"content\": prom}], temperature=0.1)\n",
        "    content = response.choices[0].message.content\n",
        "    #Remove potential markdown formatting (like ```json ... ```)\n",
        "    content = content.replace(\"```\", \"\").strip()\n",
        "    try:\n",
        "        # Attempt to find the first curly brace and slice from there\n",
        "        json_start = content.index(\"{\")\n",
        "        json_text = content[json_start:]\n",
        "        parsed_output = json.loads(json_text)\n",
        "    except (ValueError, json.JSONDecodeError) as e:\n",
        "        print(\"Error parsing JSON (explicit method):\", e)\n",
        "        return None\n",
        "    return parsed_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4EYjl4n9WUR"
      },
      "source": [
        "# Popularity of Data-Related Job Titles in the Market (Pie Chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGAaKQ5zFdXi",
        "outputId": "00a1005d-ee23-4951-92bd-48496fe8e7ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function executed successfully!\n"
          ]
        }
      ],
      "source": [
        "job_titles = df['title_name'].to_list()\n",
        "job_titles_str = \", \".join(job_titles)\n",
        "\n",
        "pie_chart_title = f\"\"\"You are given a list of job titles extracted from job descriptions: {job_titles_str}.\n",
        "### Task:\n",
        "1. **Categorize** each job title into one of the following six labels:\n",
        "   - 'Machine Learning Engineer'\n",
        "   - 'Data Scientist'\n",
        "   - 'NLP/LLM-related'\n",
        "   - 'CV Engineer'\n",
        "   - 'Other'\n",
        "2. **Count the occurrences** of each category.\n",
        "### Output:\n",
        "- Return a **JSON object** showing the count of job titles per category.\n",
        "- **Format the JSON exactly** as shown below, with no extra words or explanations:\n",
        "Example output:\n",
        "{{\"Machine Learning Engineer\": 5, \"Data Scientist\": 3, \"NLP/LLM-related\": 2, \"CV Engineer\": 1, \"Data Analyst\": 0, \"Other\": 2}}\"\"\"\n",
        "\n",
        "max_retries = 3\n",
        "attempt = 0\n",
        "pie_chart_data = None\n",
        "\n",
        "while attempt < max_retries:\n",
        "    try:\n",
        "        pie_chart_data = llm_analytics(pie_chart_title)\n",
        "        if pie_chart_data is not None:\n",
        "            print(\"Function executed successfully!\")\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "    attempt += 1\n",
        "if pie_chart_data is None:\n",
        "    print(\"Function failed after 3 attempts.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkgFhbz9WUS"
      },
      "source": [
        "# Education Requirements (Donuts Charts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3EbS-BnNg0op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f11a288-0439-4df4-8f18-900accc23d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function executed successfully!\n"
          ]
        }
      ],
      "source": [
        "requirement_education = df['education'].to_list()\n",
        "job_education_str = \", \".join(requirement_education)\n",
        "\n",
        "donut_education = f\"\"\"\n",
        "You are given a list of company requirements regarding the education level of candidates: {job_education_str}.\n",
        "\n",
        "### **Task:**\n",
        "1. **Classify each requirement** into one of the following three categories:\n",
        "   - **\"Higher_education\"** ‚Üí If the job explicitly requires a higher education degree.\n",
        "   - **\"Just_experience\"** ‚Üí If the job focuses only on experience and does not require higher education.\n",
        "   - **\"Both_required\"** ‚Üí If both higher education and experience are mandatory.\n",
        "\n",
        "2. **Count the occurrences** of each category.\n",
        "\n",
        "### **Output:**\n",
        "- Return a **JSON object** showing the frequency of each category.\n",
        "- **Strictly follow this format**, with no extra words or explanations:\n",
        "\n",
        "Example output: {{\"Higher_education\": 5, \"Just_experience\": 6, \"Both_required\": 2}}\"\"\"\n",
        "\n",
        "max_retries = 3\n",
        "attempt = 0\n",
        "donut_data = None\n",
        "\n",
        "while attempt < max_retries:\n",
        "    try:\n",
        "        donut_data = llm_analytics(donut_education)\n",
        "        if donut_data is not None:\n",
        "            print(\"Function executed successfully!\")\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "    attempt += 1\n",
        "if donut_data is None:\n",
        "    print(\"Function failed after 3 attempts.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yshIHm459WUS"
      },
      "source": [
        "# Hard skills (Barplot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FGW4-NMdSzWR"
      },
      "outputs": [],
      "source": [
        "hard_skills = df['hard_skills_technologies'].to_list()\n",
        "flattened_list = [item for sublist in hard_skills for item in sublist]\n",
        "hard_skills_str = \", \".join(flattened_list)\n",
        "\n",
        "prompt_bar_plot = f\"\"\"You are given a dataset scraped from job vacancies,\n",
        "containing technologies and hard skills required for Data Science, Machine Learning, and NLP/LLM roles.\n",
        "\n",
        "### **Your Task:**\n",
        "1. **Count** the occurrences of each unique skill or technology.\n",
        "2. **Normalize Similar Skills**:\n",
        "   - If two skills have very similar meanings (e.g., \"Model Deployment\" and \"Model Implementation in Production\"), **group them into one category** and sum their occurrences.\n",
        "   - Consider naming variations such as \"Python Scripting\" and \"Python\" as the same skill (\"Python\").\n",
        "3. **Return a JSON Object** where:\n",
        "   - **Keys** are the normalized technology/skill names.\n",
        "   - **Values** represent the number of times each skill/technology was mentioned.\n",
        "   - **Use properly escaped double quotes** for all keys and string values.\n",
        "4. **Output Only JSON**:\n",
        "   - **Do not add explanations, summaries, or extra text.**\n",
        "   - Your response should strictly follow the JSON format.\n",
        "\n",
        "### **Example Output Format:**\n",
        "{{\n",
        "  \"Python\": 11,\n",
        "  \"R\": 1,\n",
        "  \"Scikit-learn\": 4,\n",
        "  \"Anthropic Models\": 3,\n",
        "  \"Model Deployment\": 7,\n",
        "  \"TensorFlow\": 2,\n",
        "  \"CatBoost\": 1,\n",
        "  \"PostgreSQL\": 2,\n",
        "  \"Pandas\": 5,\n",
        "  \"RAG\": 4\n",
        "}}\n",
        "List with technologies/hard skills: {hard_skills_str}\"\"\"\n",
        "\n",
        "max_retries = 3\n",
        "attempt = 0\n",
        "bar_plot_data = None\n",
        "\n",
        "while attempt < max_retries:\n",
        "    try:\n",
        "        bar_plot_data = llm_analytics(prompt_bar_plot)\n",
        "        if bar_plot_data is not None:\n",
        "            print(\"Function executed successfully!\")\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "    attempt += 1\n",
        "if bar_plot_data is None:\n",
        "    print(\"Function failed after 3 attempts.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpBi-SNa9WUT"
      },
      "outputs": [],
      "source": [
        "df_hard = (\n",
        "    pd.DataFrame({\"Technologies\": list(bar_plot_data.keys()), \"Number\": list(bar_plot_data.values())})\n",
        "    .sort_values(by=\"Number\", ascending=False)\n",
        "    .reset_index(drop=True))\n",
        "df_hard[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE9Mj3gw9WUT"
      },
      "source": [
        "# Soft skills (Vertical Progress Bars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgnmsEWGigGS"
      },
      "outputs": [],
      "source": [
        "soft_skills = df['soft_skills'].to_list()\n",
        "flattened_list = [item for sublist in soft_skills for item in sublist]\n",
        "soft_skills_str = \", \".join(flattened_list)\n",
        "\n",
        "prompt_horiz_bar = f\"\"\"You are given a list of soft skills scraped from job vacancies\n",
        " in the fields of Data Science, Machine Learning, and NLP/LLM.\n",
        "\n",
        "### **Your Task:**\n",
        "1. **Count** the occurrences of each unique soft skill.\n",
        "2. **Normalize Similar Skills**:\n",
        "   - Group skills with similar meanings (e.g., \"Good communication skills\" and \"Ability to communicate effectively\") under a single category.\n",
        "   - Ensure consistent naming conventions (e.g., \"Excellent presenting skills\" vs. \"Strong presentation skills\").\n",
        "3. **Return a Dictionary** where:\n",
        "   - **Keys** are the normalized soft skill names.\n",
        "   - **Values** represent the number of times each skill was mentioned.\n",
        "   - The dictionary **must be properly formatted for parsing**.\n",
        "4. **Strict Output Formatting**:\n",
        "   - **Do not add any extra words, explanations, or text**.\n",
        "   - The response should be **a clean, parsing-ready dictionary**.\n",
        "\n",
        "### **Example Output Format:**\n",
        "{{\n",
        "    \"Advanced English\": 11,\n",
        "    \"Excellent presenting skills\": 1,\n",
        "    \"Being a team player\": 4,\n",
        "    \"Good communication skills\": 3\n",
        "}}\n",
        "List of soft skills: {soft_skills_str}\n",
        "\"\"\"\n",
        "\n",
        "max_retries = 3\n",
        "attempt = 0\n",
        "bar_plot_horiz_data = None\n",
        "\n",
        "while attempt < max_retries:\n",
        "    try:\n",
        "        bar_plot_horiz_data = llm_analytics(prompt_horiz_bar)\n",
        "        if bar_plot_horiz_data is not None:\n",
        "            print(\"Function executed successfully!\")\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "    attempt += 1\n",
        "if bar_plot_horiz_data is None:\n",
        "    print(\"Function failed after 3 attempts.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_soft = (\n",
        "    pd.DataFrame({\"Soft_skills\": list(bar_plot_horiz_data.keys()), \"Number\": list(bar_plot_horiz_data.values())})\n",
        "    .sort_values(by=\"Number\", ascending=False).reset_index(drop=True))\n",
        "\n",
        "df_soft[:3]"
      ],
      "metadata": {
        "id": "njRCE3W7gMm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKYcjN2A9WUT"
      },
      "source": [
        "# Saving All Analytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iju0JPUH9WUT"
      },
      "outputs": [],
      "source": [
        "# Saving files localy\n",
        "\n",
        "path = '/content/drive/MyDrive/Set_Uni_Analytics/'\n",
        "analytics_name = path + 'analytics' + today + '.csv'\n",
        "soft_skills_name = path + 'soft_skills' + today + '.csv'\n",
        "hard_skills_name = path + 'hard_skills' + today + '.csv'\n",
        "donut_data_name = path + 'donut_data.json'\n",
        "pie_chart_data_name = path + 'pie_chart_data.json'\n",
        "\n",
        "with open(donut_data_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(donut_data, f, indent=4)\n",
        "\n",
        "with open(pie_chart_data_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(pie_chart_data, f, indent=4)\n",
        "\n",
        "df.to_csv(analytics_name)\n",
        "df_soft.to_csv(soft_skills_name, index=False)\n",
        "df_hard.to_csv(hard_skills_name, index=False)\n",
        "print(\"Files were successfully saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUcGdbbv9WUT"
      },
      "outputs": [],
      "source": [
        "# Uploading fresh analytics to the S3 bucket\n",
        "\n",
        "BUCKET_NAME = \"data-job-market-monitoring\"\n",
        "LOCAL_FOLDER = \"job_analytics/\"\n",
        "S3_FOLDER = \"job_analytics\" + today + \"/\"\n",
        "\n",
        "def upload_files_to_s3():\n",
        "    \"\"\"\n",
        "    Upload all files from LOCAL_FOLDER to S3.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(LOCAL_FOLDER):\n",
        "        print(f\"Error: Folder '{LOCAL_FOLDER}' does not exist!\")\n",
        "        return\n",
        "    # Walk through local folder and upload each file\n",
        "    for root, _, files in os.walk(LOCAL_FOLDER):\n",
        "        for file_name in files:\n",
        "            local_file_path = os.path.join(root, file_name)\n",
        "            s3_key = os.path.relpath(local_file_path, LOCAL_FOLDER)\n",
        "            s3_key = os.path.join(S3_FOLDER, s3_key).replace(\"\\\\\", \"/\")\n",
        "            try:\n",
        "                print(f\"Uploading {local_file_path} to s3://{BUCKET_NAME}/{s3_key}...\")\n",
        "                s3.upload_file(local_file_path, BUCKET_NAME, s3_key)\n",
        "                print(\"Upload successful!\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to upload {local_file_path}: {e}\")\n",
        "    print(\"\\nAll files have been uploaded to S3!\")\n",
        "\n",
        "# Run the upload function\n",
        "upload_files_to_s3()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}